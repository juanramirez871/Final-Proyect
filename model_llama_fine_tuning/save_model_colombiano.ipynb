{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cecd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e3df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "LORA_PATH = \"../model_llama_fine_tuning/llama_colombiano_LoRA\"\n",
    "OUTPUT_PATH = \"./llama_colombiano_merged\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a371681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "login(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a27d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cpu\"\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(model, LORA_PATH)\n",
    "model = model.merge_and_unload()\n",
    "model.save_pretrained(OUTPUT_PATH)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "tokenizer.save_pretrained(OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
